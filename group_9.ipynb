{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Summer School - Group 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Group Members:</b><br />\n",
    "- Alexander Velev, Task 3<br />\n",
    "- Daria Bidenko, Task 1 and 4<br />\n",
    "- Giel Intven, Task33<br />\n",
    "- Hamza Mulahmetovic, Task 1 and 2<br />\n",
    "- Malin Rudin, Task 2 and 4<br />\n",
    "\n",
    "All members took part in the whole creation of the project<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 – The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are x-ray images taken in the chest region of children aged 1-5 from the\n",
    "Guangzhou Women and Children’s Medical Center. There are 1100 images of healthy\n",
    "humans, as well as 1100 images of people with pneumonia.\n",
    "Keep in mind, that the image format is jpeg, and there are 3 color channels.\n",
    "You need to organize the data into directories as shown on Figure 1. You need to determine\n",
    "the training/validation/testing split yourselves but need to justify your split choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the origin path where the raw files were saved\n",
    "source_dir = 'data/'\n",
    "# define a structure as defined in the task. one folder for training, validation and testing.\n",
    "training_dir = 'data/training/'\n",
    "validation_dir = 'data/validation/'\n",
    "testing_dir = 'data/testing/'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(training_dir + 'normal', exist_ok=True)\n",
    "os.makedirs(training_dir + 'pneumonia', exist_ok=True)\n",
    "os.makedirs(validation_dir + 'normal', exist_ok=True)\n",
    "os.makedirs(validation_dir + 'pneumonia', exist_ok=True)\n",
    "os.makedirs(testing_dir + 'normal', exist_ok=True)\n",
    "os.makedirs(testing_dir + 'pneumonia', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all files in two separate arrays by file name\n",
    "normal_files = [f for f in os.listdir(source_dir) if '_normal' in f]\n",
    "pneumonia_files = [f for f in os.listdir(source_dir) if '_pneumonia' in f]\n",
    "\n",
    "# split the files into groups\n",
    "# 75% for training, 15% for testing, 10% for validation\n",
    "# we will keep the majority of the data for training to allow the creation of a robust model\n",
    "# but also allocate enough data for testing to evaluate performance and to prevent overfitting\n",
    "def split_files(files, train_ratio=0.75, test_ratio=0.15):\n",
    "    total_files = len(files)\n",
    "    train_split = floor(total_files * train_ratio)\n",
    "    test_split = floor(total_files * test_ratio)\n",
    "    \n",
    "    # shuffle the files to ensure randomness in the split\n",
    "    random.shuffle(files)\n",
    "    \n",
    "    train_files = files[:train_split]\n",
    "    test_files = files[train_split:train_split + test_split]\n",
    "    val_files = files[train_split + test_split:]\n",
    "    \n",
    "    return train_files, test_files, val_files\n",
    "\n",
    "normal_train, normal_test, normal_val = split_files(normal_files)\n",
    "pneumonia_train, pneumonia_test, pneumonia_val = split_files(pneumonia_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the gathered files to the belonging folders\n",
    "def move_files(files, dest_dir):\n",
    "    for f in files:\n",
    "        shutil.move(os.path.join(source_dir, f), os.path.join(dest_dir, f))\n",
    "\n",
    "# Move normal files\n",
    "move_files(normal_train, training_dir + 'normal/')\n",
    "move_files(normal_test, testing_dir + 'normal/')\n",
    "move_files(normal_val, validation_dir + 'normal/')\n",
    "\n",
    "# Move pneumonia files\n",
    "move_files(pneumonia_train, training_dir + 'pneumonia/')\n",
    "move_files(pneumonia_test, testing_dir + 'pneumonia/')\n",
    "move_files(pneumonia_val, validation_dir + 'pneumonia/')\n",
    "\n",
    "print(\"Files have been successfully organized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count files in a directory\n",
    "def count_files(directory):\n",
    "    normal_count = len(os.listdir(os.path.join(directory, 'normal')))\n",
    "    pneumonia_count = len(os.listdir(os.path.join(directory, 'pneumonia')))\n",
    "    return normal_count, pneumonia_count\n",
    "\n",
    "# Collect file counts to verify if everything was done correctly\n",
    "train_normal, train_pneumonia = count_files(training_dir)\n",
    "val_normal, val_pneumonia = count_files(validation_dir)\n",
    "test_normal, test_pneumonia = count_files(testing_dir)\n",
    "\n",
    "# Prepare data for plotting\n",
    "categories = ['Training', 'Validation', 'Testing']\n",
    "normal_counts = [train_normal, val_normal, test_normal]\n",
    "pneumonia_counts = [train_pneumonia, val_pneumonia, test_pneumonia]\n",
    "\n",
    "# Plot the results\n",
    "x = range(len(categories))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x, normal_counts, width=0.4, label='Normal', color='blue', align='center')\n",
    "plt.bar(x, pneumonia_counts, width=0.4, label='Pneumonia', color='red', align='edge')\n",
    "\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Distribution of Images in Training, Validation, and Testing Sets')\n",
    "plt.xticks(x, categories)\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 – Data Loading and Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the data from task 1, using the CustomDataset class we can load the data into the model, using torch DataLoader.\n",
    "The data augmentation consists of a random horizontal flip, a random rotation up to 20 degrees and an affine transformation to make the model more robust for random patient oerientation. The randomaffine transform makes the model more robust. A scalejitter transformation makes the model more robust to images taken at different scales. Gaussian blur and noise make the model more robust to imperfect data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the global variables\n",
    "input_dim=(256,256) # set the input dimension of the images to 256x256\n",
    "channel_dim=1 # 1 for greyscale, 3 for RGB (We are using greyscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the GPU if available to speed up the training (especially for google colab)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have to generate a dataset using de Dataset class. We got this code from the Exercise 5 solution. \n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_size, class_names, path=None, transformations=None, num_per_class: int = -1):\n",
    "        self.img_size = img_size\n",
    "        self.path = path\n",
    "        self.num_per_class = num_per_class\n",
    "        self.class_names = class_names\n",
    "        self.transforms = transformations\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "\n",
    "        if path:\n",
    "            self.readImages()\n",
    "\n",
    "        self.standard_transforms = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "            ])\n",
    "\n",
    "    def readImages(self):\n",
    "        for id, class_name in self.class_names.items():\n",
    "            print(f'Loading images from class: {id} : {class_name}')\n",
    "            img_path = glob.glob(f'{self.path}{class_name}/*.jpg')\n",
    "            if self.num_per_class > 0:\n",
    "                img_path = img_path[:self.num_per_class]\n",
    "            self.labels.extend([id] * len(img_path))\n",
    "            for filename in img_path:\n",
    "                img = Image.open(filename).convert('L')\n",
    "                img = img.resize(self.img_size)\n",
    "                self.data.append(img)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        else:\n",
    "            img = self.standard_transforms(img)\n",
    "\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#After testing several types of data augmentation we found out the performance only got worse, so we used none.\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #We tested image flipping, noise addition, gaussian bluring, image scaling, contrast enhancement...\n",
    "])\n",
    "\n",
    "train_path = \"data/training/\"\n",
    "test_path = \"data/testing/\"\n",
    "validation_path = \"data/validation/\"\n",
    "\n",
    "#Getting the class names from the training set\n",
    "class_names = [name[len(train_path):] for name in glob.glob(f'{train_path}*')]\n",
    "class_names = dict(zip(range(len(class_names)), class_names))\n",
    "\n",
    "#Generating the datasets and dataloaders for the model\n",
    "train_dataset = CustomDataset(img_size=input_dim, path=train_path, class_names=class_names, transformations=train_transform) #We only applied transformations to the training set\n",
    "test_dataset = CustomDataset(img_size=input_dim, path=test_path, class_names=class_names)\n",
    "validation_dataset = CustomDataset(img_size=input_dim, path=validation_path, class_names=class_names)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 – Construction the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After successfully creating both the custom dataset and the dataloader, you need to create a\n",
    "neural network, and use the data loader to feed the network. The architecture, complexity and\n",
    "regularization are all up to you, but you need to justify your choices in comments. You are\n",
    "more than welcome to replicate already known architectures or architectures we made during\n",
    "the course, but you are NOT allowed to use any pretrained networks. You are also not\n",
    "allowed to use any training data that is not included on ItsLearning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carefully consider which hyperparameters to test and strategically try to find the optimal\n",
    "architecture for the task. In the comments, please describe your method for the optimization\n",
    "and your choice of hyperparameters. Remember that there is an underlying competition, and\n",
    "the highest accuracy wins. The competition will be measured based on the saved model, so\n",
    "make sure to submit only the best one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports again... Just in case\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables\n",
    "input_dim = (256, 256)  # Input dimension of the images (e.g., 256x256 pixels)\n",
    "channel_dim = 1         # Number of input channels (1 for grayscale, 3 for RGB)\n",
    "\n",
    "class group_9(nn.Module):\n",
    "    \"\"\"\n",
    "    A convolutional neural network (CNN) model for binary classification.\n",
    "\n",
    "    This class defines a neural network designed for classifying grayscale chest x-ray images \n",
    "    into two categories: healthy and pneumatic. It consists of two convolutional layers followed \n",
    "    by a series of fully connected layers. The network includes dropout layers for regularization \n",
    "    and ReLU activations for non-linearity.\n",
    "\n",
    "    Pneumonia causes inflammation of the lungs' air sacs, which fill up with fluid. \n",
    "    This fluid is denser than the air in the lungs and absorbs more x-rays, resulting in white spots \n",
    "    on the x-ray image. The model aims to detect these opaque spots. Convolutional layers with \n",
    "    different kernel sizes allow the model to capture patterns at various scales. After the convolutional \n",
    "    layers, the data is flattened and passed through three hidden layers. Dropout layers are used \n",
    "    between hidden layers to prevent overfitting. The chosen dropout rate is 0.3, based on experimentation \n",
    "    and results. The model's input dimensions are 256x256 to balance accuracy and training efficiency.\n",
    "\n",
    "    Architecture:\n",
    "    - Convolutional Layer (conv1): Applies 32 convolutional filters of size 5x5 to the input.\n",
    "    - Convolutional Layer (conv2): Applies 64 convolutional filters of size 3x3.\n",
    "    - Max Pooling Layer (maxpool1): Reduces spatial dimensions by pooling with a 2x2 kernel.\n",
    "    - Fully Connected Layer (fc1): Transforms the flattened output to 512 units.\n",
    "    - Fully Connected Layer (fc2): Further transforms the data to 128 units.\n",
    "    - Fully Connected Layer (fc3): Reduces the data to 64 units.\n",
    "    - Fully Connected Layer (fc4): Outputs 2 units representing the final class scores.\n",
    "    - Dropout Layers: Applied after each fully connected layer to prevent overfitting.\n",
    "    - ReLU Activations: Introduce non-linearity after each convolutional and fully connected layer.\n",
    "    - Softmax Activation: Outputs probability distribution over the two classes.\n",
    "\n",
    "    Attributes:\n",
    "        conv1 (nn.Conv2d): The first convolutional layer.\n",
    "        conv2 (nn.Conv2d): The second convolutional layer.\n",
    "        maxpool1 (nn.MaxPool2d): The max pooling layer.\n",
    "        fc1 (nn.Linear): The first fully connected layer.\n",
    "        fc2 (nn.Linear): The second fully connected layer.\n",
    "        fc3 (nn.Linear): The third fully connected layer.\n",
    "        fc4 (nn.Linear): The final fully connected layer.\n",
    "        dropout (nn.Dropout): Dropout layer for regularization.\n",
    "        relu (nn.ReLU): ReLU activation function.\n",
    "        softmax (nn.Softmax): Softmax activation function for output probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the network layers and components.\n",
    "        \n",
    "        Sets up the convolutional layers, max pooling, fully connected layers, dropout layers,\n",
    "        and activation functions according to the architecture defined for the network.\n",
    "        \"\"\"\n",
    "        super(group_9, self).__init__()\n",
    "        \n",
    "        # Two convolutional layers to detect patterns in the images\n",
    "        self.conv1 = nn.Conv2d(in_channels=channel_dim, out_channels=32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Correct the input size for fc1 based on the calculations\n",
    "        self.fc1 = nn.Linear(64 * 125 * 125, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 2)\n",
    "        # 0.3 dropout to reduce overfitting\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, channel_dim, height, width), where\n",
    "                                batch_size is the number of images in a batch, channel_dim is the number\n",
    "                                of input channels (e.g., grayscale), and height and width are the dimensions \n",
    "                                of the images.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (batch_size, 2) where each value represents the \n",
    "                            probability of the input belonging to one of the two classes.\n",
    "        \"\"\"\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxpool1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = group_9()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "pbar = None\n",
    "def train(model, num_epochs: int = 3):\n",
    "    for epoch in range(num_epochs):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.train()\n",
    "\n",
    "        pbar = tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\", leave=True)\n",
    "\n",
    "        for data, targets in train_dataloader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            current_accuracy = correct / total * 100\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(accuracy=f\"{current_accuracy:.2f}%\")\n",
    "\n",
    "        pbar.close()\n",
    "        tqdm.write(f\"Epoch {epoch + 1}/{num_epochs}, Training accuracy: {current_accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        correct_validation = 0\n",
    "        total_validation = 0\n",
    "        with torch.no_grad():\n",
    "            for data, targets in validation_dataloader:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                outputs = model(data)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_validation += targets.size(0)\n",
    "                correct_validation += (predicted == targets).sum().item()\n",
    "\n",
    "        validation_accuracy = 100 * correct_validation / total_validation\n",
    "        print(f'Validation accuracy: {validation_accuracy}%')\n",
    "        torch.save(model.state_dict(), f'drive/MyDrive/SDU_Data/models/model_weights_3_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_dataloader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89514ef933874347b23204954617086f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Training accuracy: 53.05%\n",
      "Validation accuracy: 50.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6319096be7264b689d2925758db0c69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15, Training accuracy: 58.97%\n",
      "Validation accuracy: 90.9090909090909%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc228ba192c2428db3c32f8efd262bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15, Training accuracy: 77.59%\n",
      "Validation accuracy: 91.81818181818181%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d068eb58002944c495f5a30baf0ad712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15, Training accuracy: 87.41%\n",
      "Validation accuracy: 92.72727272727273%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd55b004df13474aa036462693da489b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15, Training accuracy: 88.45%\n",
      "Validation accuracy: 94.0909090909091%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f700597fe2984be9ac6baad9206e2d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15, Training accuracy: 90.23%\n",
      "Validation accuracy: 75.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31c9edcf411473695414cf61bcd9388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15, Training accuracy: 89.37%\n",
      "Validation accuracy: 94.0909090909091%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd1106d3b5648db9673f3801234b76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15, Training accuracy: 92.24%\n",
      "Validation accuracy: 94.0909090909091%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcfc47fdc47c44b298d07087bdd4ab4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15, Training accuracy: 91.90%\n",
      "Validation accuracy: 95.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eccc773c6b5440baa5d93edb0cac653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15, Training accuracy: 92.70%\n",
      "Validation accuracy: 92.72727272727273%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8ad741a4894eae88d44a517a2fe9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15, Training accuracy: 93.51%\n",
      "Validation accuracy: 93.63636363636364%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfebb5fcd414519b522967a62c335fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15, Training accuracy: 93.74%\n",
      "Validation accuracy: 95.45454545454545%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc886d5650d4d4ea5b16a6f9d0ea66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15, Training accuracy: 94.02%\n",
      "Validation accuracy: 95.45454545454545%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e6e91774794e35a9f53602de074083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15, Training accuracy: 94.20%\n",
      "Validation accuracy: 92.72727272727273%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39f08fdfdcd424bb8333e8800b13d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/15:   0%|          | 0/1740 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15, Training accuracy: 95.29%\n",
      "Validation accuracy: 95.45454545454545%\n",
      "Test Accuracy: 92.73%\n"
     ]
    }
   ],
   "source": [
    "train(model=model, num_epochs=15)\n",
    "test(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'group_9.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 - Visualizing your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you must visualize some aspects of your model. It can be a graph of the\n",
    "training/validation performance, visualization of the filters or feature maps, or anything you\n",
    "can think of. This must be saved as an image file and uploaded along with your model and\n",
    "code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENTS: We were not able to show the two last plottings with the GPU we had left but from our most succesful version er have hard coded a training/validation graph below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = np.array([0.5305, 0.5897, 0.7759, 0.8741, 0.8845, 0.9023, 0.8937, 0.9224,\n",
    " 0.919 , 0.927 , 0.9351, 0.9374, 0.9402, 0.942 , 0.9529]) # Our most successful epoch was number 12\n",
    "\n",
    "validation_accuracy = np.array([0.5   , 0.9091, 0.9182, 0.9273, 0.9409, 0.75  , 0.9409, 0.9409,\n",
    " 0.95  , 0.9273, 0.9364, 0.9545, 0.9545, 0.9273, 0.9545])\n",
    "\n",
    "epochs = range(1, len(training_accuracy) + 1) # Making a range from 1 to the length of our array to get number of epochs\n",
    "\n",
    "plt.plot(epochs, training_accuracy, 'b', label=f'Training Accuracy')\n",
    "plt.plot(epochs, validation_accuracy, 'g', label=f'Validation Accuracy')\n",
    "plt.title(f'Training and Validation Accuracy' )\n",
    "plt.xlabel(f'Epochs')\n",
    "plt.ylabel(f'Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for training/validation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_data = np.array([1, 2, 3]) ## TODO: INPUT REAL NUMBERS\n",
    "Validation_data = np.array([1, 2, 3]) ## TODO: INPUT REAL NUMBERS\n",
    "\n",
    "def plot_metric(metric_name, training_array, validation_array):\n",
    "    \"\"\"\n",
    "    Plots the given metric for both training and validation data using Matplotlib.\n",
    "    \n",
    "    Parameters:\n",
    "    - metric_name: The name of the metric to plot (e.g., 'loss' or 'accuracy').\n",
    "    - training_array: array of the loss/accuracy values for each epoch collected from training set.\n",
    "    - validation_array: array of the loss/accuracy values for each epoch collected from validation set.\n",
    "    \"\"\"\n",
    "\n",
    "                    \n",
    "    num_epochs = len(training_array) #getting the amount of epoches from an input array\n",
    "    epochs = range(1, num_epochs + 1) #sequence of epoch numbers for the plot\n",
    "    plt.plot(epochs, training_array, 'b', label=f'Training {metric_name}')\n",
    "    plt.plot(epochs, validation_array, 'g', label=f'Validation {metric_name}')\n",
    "    plt.title(f'Training and Validation {metric_name}' )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(f' {metric_name}')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix - detecting true and false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We need true/false positives/negatives\n",
    "\n",
    "actual_labels = [1, 0, 1, 0, 1, 1, 1, 1] # TODO: make this real vector\n",
    "predicted_labels = [0, 1, 1, 0, 1, 1, 1, 1] # TODO: make this real vector\n",
    "\n",
    "\n",
    "def show_confusion_matrix(actual_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    This function prints the confusion matrix.\n",
    "    :param actual_labels: array of 1(label 'Pneumonia') and 0(label 'Healthy') given with dataset.\n",
    "    :param predicted_labels: array of 1(label 'Pneumonia') and 0(label 'Healthy') predicted by model.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(actual_labels, predicted_labels)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=['Healthy', 'Pneumonia'], \n",
    "            yticklabels=['Healthy', 'Pneumonia'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "show_confusion_matrix(actual_labels, predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
