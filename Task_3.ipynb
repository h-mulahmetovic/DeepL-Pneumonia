{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 â€“ Construction the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After successfully creating both the custom dataset and the dataloader, you need to create a\n",
    "neural network, and use the data loader to feed the network. The architecture, complexity and\n",
    "regularization are all up to you, but you need to justify your choices in comments. You are\n",
    "more than welcome to replicate already known architectures or architectures we made during\n",
    "the course, but you are NOT allowed to use any pretrained networks. You are also not\n",
    "allowed to use any training data that is not included on ItsLearning.\n",
    "Carefully consider which hyperparameters to test and strategically try to find the optimal\n",
    "architecture for the task. In the comments, please describe your method for the optimization\n",
    "and your choice of hyperparameters. Remember that there is an underlying competition, and\n",
    "the highest accuracy wins. The competition will be measured based on the saved model, so\n",
    "make sure to submit only the best one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "#from torchvision import datasets, transforms\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = 3\n",
    "greyscale = 1\n",
    "h, w = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=(h,w)\n",
    "channel_dim=greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from class: 0 : normal\n",
      "Loading images from class: 1 : pneumonia\n",
      "Loading images from class: 0 : normal\n",
      "Loading images from class: 1 : pneumonia\n",
      "Loading images from class: 0 : normal\n",
      "Loading images from class: 1 : pneumonia\n"
     ]
    }
   ],
   "source": [
    "# From Task 2\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_size, class_names, path=None, transformations=None, num_per_class: int = -1):\n",
    "        self.img_size = img_size\n",
    "        self.path = path\n",
    "        self.num_per_class = num_per_class\n",
    "        self.class_names = class_names\n",
    "        self.transforms = transformations\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "\n",
    "        if path:\n",
    "            self.readImages()\n",
    "\n",
    "        self.standard_transforms = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "            ])\n",
    "\n",
    "    def readImages(self):\n",
    "        for id, class_name in self.class_names.items():\n",
    "            print(f'Loading images from class: {id} : {class_name}')\n",
    "            img_path = glob.glob(f'{self.path}{class_name}/*.jpg')\n",
    "            if self.num_per_class > 0:\n",
    "                img_path = img_path[:self.num_per_class]\n",
    "            self.labels.extend([id] * len(img_path))\n",
    "            for filename in img_path:\n",
    "                img = Image.open(filename).convert('L')\n",
    "                img = img.resize(self.img_size)\n",
    "                self.data.append(img)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        else:\n",
    "            img = self.standard_transforms(img)\n",
    "\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "    \n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.RandomAffine(degrees=20, translate=(0.1, 0.1)),\n",
    "    # transforms.v2.ScaleJitter(target_scale=img_size, scale_range=(0.9, 1.1)),\n",
    "    transforms.RandomAutocontrast(p=0.25),\n",
    "    # transforms.GaussianBlur(kernel_size=3, sigma=(0,2.0)),\n",
    "    # transforms.GaussianNoise(kernel_size=3, std=0.1)\n",
    "])\n",
    "\n",
    "train_path = \"./data/training/\"\n",
    "test_path = \"./data/testing/\"\n",
    "validation_path = \"./data/validation/\"\n",
    "img_size=(256,256)\n",
    "\n",
    "\n",
    "class_names = [name[len(train_path):] for name in glob.glob(f'{train_path}*')]\n",
    "class_names = dict(zip(range(len(class_names)), class_names))\n",
    "\n",
    "train_dataset = CustomDataset(img_size=img_size, path=train_path, class_names=class_names, transformations=train_transform)\n",
    "test_dataset = CustomDataset(img_size=img_size, path=test_path, class_names=class_names)\n",
    "validation_dataset = CustomDataset(img_size=img_size, path=validation_path, class_names=class_names)\n",
    "# We could add batches to the DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class group_9(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(group_9, self).__init__()        \n",
    "\n",
    "        # Convolutional Block 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)  # Adjust `channel_dim` to 1 if needed\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolutional Block 2\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolutional Block 3\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 128)  # Updated size\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional Block 1\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        # Convolutional Block 2\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        # Convolutional Block 3\n",
    "        x = torch.relu(self.conv5(x))\n",
    "        x = torch.relu(self.conv6(x))\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        # Flattening\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group_9(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=100352, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = group_9()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs: int = 10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "    model.to(device=device)\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for data, targets in train_dataloader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_dataloader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7495371103286743\n",
      "Epoch 2/10, Loss: 0.6972017288208008\n",
      "Epoch 3/10, Loss: 0.7029154896736145\n",
      "Epoch 4/10, Loss: 0.6435468792915344\n",
      "Epoch 5/10, Loss: 0.6822442412376404\n",
      "Epoch 6/10, Loss: 0.7279707789421082\n",
      "Epoch 7/10, Loss: 0.7225052118301392\n",
      "Epoch 8/10, Loss: 0.6705479025840759\n",
      "Epoch 9/10, Loss: 0.6867930889129639\n",
      "Epoch 10/10, Loss: 0.7072901725769043\n",
      "Test Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "train(model=model, num_epochs=10)\n",
    "test(model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
